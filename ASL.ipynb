{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0acce945-6cc4-4e6f-9b07-b99b674c984f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d0018e-8735-48bb-aa92-bb277338734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./ASL Dataset\" # <-- change to the path where your `train` and `test` folders live\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "TEST_DIR = os.path.join(DATA_DIR, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f038d5-38ac-4326-aa22-98e64751521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (128, 128) # image size used for training (change to 224 for larger models)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "SEED = 42\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "NUM_CLASSES = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59030e5-1089-4524-837d-45d401832e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    validation_split=0.2,\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b11bef-aef3-4352-b445-eacdafa0e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    validation_split=0.2,\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2643247-0b1b-44c5-8772-0e54d20c0a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "NUM_CLASSES = len(class_names)\n",
    "print(f\"Found {NUM_CLASSES} classes:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e4ad07-7ba4-4de9-93be-08b2c6aa2450",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6acd56b-f54b-400d-97aa-bb4e21c783e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "layers.RandomFlip(\"horizontal\"),\n",
    "layers.RandomRotation(0.08),\n",
    "layers.RandomZoom(0.08),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9212451-0b20-478f-b431-4c2707ca7a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(*IMG_SIZE, 3))\n",
    "\n",
    "\n",
    "x = data_augmentation(inputs)\n",
    "# rescale to [0,1]\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "\n",
    "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = keras.Model(inputs, outputs, name='asl_cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1725a6-6e0e-456d-b2ba-5cb2eaeaa296",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ae1268-fe58-4284-b26a-182501eee2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f634d0-38d8-46f6-b14a-e558d0356c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"asl_best.h5\", save_best_only=True, monitor='val_accuracy', mode='max'),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e8ec3c-3b50-49c8-a756-f1df0efc20a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcede2ee-e465-4803-91c7-201e89731e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history.get('accuracy', [])\n",
    "val_acc = history.history.get('val_accuracy', [])\n",
    "loss = history.history.get('loss', [])\n",
    "val_loss = history.history.get('val_loss', [])\n",
    "\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='train acc')\n",
    "plt.plot(epochs_range, val_acc, label='val acc')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='train loss')\n",
    "plt.plot(epochs_range, val_loss, label='val loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0a84f0-b08e-4aab-af89-15707ecf9616",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('asl_saved_model')\n",
    "print('Saved model to asl_saved_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe1d64f-7bce-4b60-82ed-5b332f2a748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# %%\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "def predict_image(img_path, model, img_size=IMG_SIZE, class_names=None):\n",
    "img = image.load_img(img_path, target_size=img_size)\n",
    "arr = image.img_to_array(img)\n",
    "arr = arr / 255.0\n",
    "arr = np.expand_dims(arr, axis=0)\n",
    "preds = model.predict(arr)\n",
    "top_idx = np.argmax(preds[0])\n",
    "prob = preds[0][top_idx]\n",
    "label = class_names[top_idx] if class_names is not None else str(top_idx)\n",
    "return label, float(prob)\n",
    "\n",
    "\n",
    "# load best weights if saved by checkpoint\n",
    "if os.path.exists('asl_best.h5'):\n",
    "print('Loading best weights from asl_best.h5')\n",
    "model.load_weights('asl_best.h5')\n",
    "\n",
    "\n",
    "# loop through images in test dir (non-recursive)\n",
    "if os.path.isdir(TEST_DIR):\n",
    "test_images = [os.path.join(TEST_DIR, f) for f in os.listdir(TEST_DIR)\n",
    "if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "\n",
    "for p in test_images:\n",
    "label, prob = predict_image(p, model, class_names=class_names)\n",
    "print(f\"{os.path.basename(p)} -> {label} ({prob:.3f})\")\n",
    "else:\n",
    "print('Test directory not found at', TEST_DIR)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Using NumPy to build a manual mini-batch for debugging (optional)\n",
    "#\n",
    "# If you want to quickly debug a single batch using NumPy arrays (e.g., for unit tests), here's how to take a batch from the dataset and convert to NumPy:\n",
    "\n",
    "\n",
    "# %%\n",
    "for images_batch, labels_batch in train_ds.take(1):\n",
    "images_np = images_batch.numpy()\n",
    "labels_np = labels_batch.numpy()\n",
    "print('images_np.shape =', images_np.shape)\n",
    "print('labels_np.shape =', labels_np.shape)\n",
    "break\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Next steps / improvements\n",
    "# - Replace the simple CNN with a MobileNetV2 / EfficientNet backbone for much better accuracy on small datasets (use `tf.keras.applications`).\n",
    "# - Use class weights if your dataset is imbalanced.\n",
    "# - Add stratified splitting or ensure each class appears in validation set.\n",
    "# - Consider using `tf.data` pipelines loading images directly and applying augmentation for very large datasets.\n",
    "# - If you plan to deploy on mobile, test the TFLite conversion and quantize the model.\n",
    "\n",
    "\n",
    "# EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd688ebd-c898-47b2-a4f0-4967fcf20993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1049bc7c-cf5c-43f1-b693-d9366bef9215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f873d251-7cf5-48b4-8691-5f9a22d73814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9c23f7-18fc-474b-a3b9-98db7a4c407b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
